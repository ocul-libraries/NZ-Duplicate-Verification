# NZ-Duplicate-Verification
This project compares publisher, publication data, and edition statements in bibliographic records to verify true duplicates before merging. It uses a CSV input and JSON transformation rules, then outputs a a merge-combine.csv file that can be used with Alma's built in Merge Records and Combine Inventory job.

The CSV input file can be exported from the shared Alma Analytic:
/Shared Folders/UTON Network 01OCUL_NETWORK/Reports/NZ Duplicates - for script/NZ Duplicates - TEMPLATE

# Requirements
Python: 3.8 or higher

Libraries (install via pip):
- pandas 
- openpyxl 
- xlsxwriter

# Files & Folders

**`main folder/`**
- **`data/`** → This is where you will store the CSV export from Alma Analytics.
- **`json/`** → Transformation rules (publisher edits, publication date edits).  
- **`output/`** → Files generated by script will be stored here.
- **`config.json`** → Defines file paths. If you want to change filenames or folders, update config.json accordingly.
- **`ocul-cf_nz_duplicate_verification.py`** → Main script that processes the data.  

# Usage
- Export CSV file from the Alma Analytic 
- Create a data/ folder and an output/ folder in the same folder as the python script, json/ folder, and cong.json file.
- Place the CSV file in the data/ folder.
- Run the script: ocul-cf_nz_duplicate_verification.py
- Final mapped CSV is in the output/ folder (merge-combine.csv)
